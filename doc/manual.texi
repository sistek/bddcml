\input texinfo  @c                                  -*- Texinfo -*-
@setfilename bddcml.info

@ifinfo
@format
START-INFO-DIR-ENTRY
* BDDCML: (bddcml).		A Multi-Level Balancing Domain Decomposition by Constraints solver library.
END-INFO-DIR-ENTRY
@end format

@end ifinfo

@iftex
@c @finalout
@settitle BDDCML
@titlepage
@title BDDCML
@subtitle solver library based on Multi-Level Balancing Domain Decomposition by Constraints
@subtitle copyright (C) 2010-2012 Jakub @v{S}@'{@dotless{i}}stek
@subtitle version 2.1
@author Jakub @v{S}@'{@dotless{i}}stek

@end titlepage

@parindent 0mm
@parskip 2mm

@end iftex
@node Top,,, (dir)

@c table of contents
@contents

@chapter Introduction

The BDDCML (Balancing Domain Decomposition by Constraints - Multi-Level) is a library for solving large sparse linear systems resulting from 
computations by the finite element method (FEM). 
Domain decomposition technique is employed which allows distribution of the computations among processors.

The main goal of the package is to provide a scalable implementation of the (Adaptive) Multilevel BDDC method. 
Codes are written in Fortran 95 with MPI library. 
A library is provided, which is supposed to be called from users' applications. 
It provides a simple interface functions callable from Fortran and C. 

Balancing Domain Decomposition by Constraints (BDDC) has quickly evolved into a very popular method. However, for very large numbers of subdomain, the coarse problem becomes a large problem to be solved in its own right. In Multilevel BDDC, the coarse problem is solved only approximately by recursive application of BDDC to higher levels.

The main web site of the BDDCML project is

@uref{http://www.math.cas.cz/~sistek/software/bddcml.html}

In case of questions, reporting a bug, or just of interest, feel free to contact 
Jakub @v{S}@'{@dotless{i}}stek 
at
@email{sistek@@math.cas.cz}.


@chapter How to use @code{BDDCML}

The library provides a simple interface callable from Fortran and C. 
Although main parts of the solver are purely algebraic, the solver needs also to get some information of the computational mesh.
This requirement is mainly motivated by selection of corners within the method, for which existing algorithms rely on geometry.

Two different modes are possible for input:
@itemize
@item user can either provide information about global mesh and a file with element matrices (global loading),
@item user can provide division into subdomains on the first level and pass 
  subdomain matrices for each subdomain to the routine (local loading).
@end itemize

The solution process is divided into the following sequence of called functions.
Their parameters are described in separate sections.

@enumerate
@item @code{bddcml_init} -- initialization of the solver
@item
@itemize
@item @code{bddcml_upload_global_data} -- loading global data about computational mesh and matrix (use for global loading)
@item @code{bddcml_upload_subdomain_data} -- loading data for one subdomain mesh and matrix (use for local loading)
@end itemize
@item @code{bddcml_setup_preconditioner} -- prepare preconditioner 
@item @code{bddcml_solve} -- solve loaded system by precodnitioned Krylov subspace iterative method (PCG or BiCGstab)
@item 
@itemize
@item @code{bddcml_download_local_solution} -- get the solution restricted to a subdomain from the solver (use for local loading)
@item @code{bddcml_download_global_solution} -- get the global solution from the solver (use for global loading)
@end itemize
@item @code{bddcml_finalize} -- clear solver data and deallocate memory
@end enumerate

Two examples are presented in the @file{examples} folder. Both are written in Fortran 90. 
The @file{bddcml_global.f90} demonstrates the use of global input, while the @file{bddcml_local.f90} demonstrates the use of localized subdomain input.
Optionally, one can ask for nodal reactions at Dirichlet boundary conditions by 
@itemize
@item @code{bddcml_download_local_reactions} -- get the reactions restricted to a subdomain from the solver (use for local loading)
@item @code{bddcml_download_global_reactions} -- get the global reactions from the solver (use for global loading)
@end itemize

@chapter Notes for C/C++ users

Since @code{BDDCML} is written in Fortran 95 language, users who want to use BDDCML from C/C++ need to 
overcome a few issues related to this fact.

@section @code{Header file}
There is a C interface provided in the file @file{bddcml_interface_c.h} that has to be included in applications.
In C++, users should include this file using the @code{extern} directive as

@verbatim
extern "C" { 
    #include <bddcml_interface_c.h>
}
@end verbatim

@section @code{Cross-compilation}
Fortran compilers change the name of subroutines as they appear in the code when they generate symbols out of them
(this is mainly related to historical reasons).
Some Fortran compilers append `@code{_}' at the end of the name, some append `@code{__}', some do not do anything to the name and
some change all letters to upper case.
In order to combine C and Fortran code, it is necessary to mimic the behaviour of the Fortran compiler in a C/C++ code by 
modifying names of the C functions (both when calling Fortran routine from a C function and vice versa). 
For a somewhat generic behaviour of this naming convention, there is an @code{F_SYMBOL} macro defined in @file{bddcml_interface_c.h}
which changes the C names to match the name expected by Fortran. 
This is based on a preprocessor variable used in compiling C/C++ code.
Possible values include:
@itemize
@item     @code{Add_}  - append `@code{_}' at the end of the function name (this is most common and used e.g. by @code{gfortran} or @code{Intel Fortran Compiler})
@item     @code{Add__} - append `@code{__}' at the end of the function name (used e.g. by @code{g95})
@item     @code{UPPER} - change all letters to uppercase
@end itemize
This should appear on command line as e.g. @code{-DAdd_} during compiling.
If nothing is defined, no change is done to the symbol name, which is in fact correct for certain Fortran compilers, 
such as those by @code{IBM}.

@section @code{Libraries of Fortran compiler}
If C code is called from Fortran, no additional libraries are usually needed. 
However, in the opposite case, i.e. the one encountered if @code{BDDCML} is used from a C/C++ code,
one needs to explicitly specify the libraries of Fortran compiler in the linking sequence when the 
final executable is build by a C++ linker. 
For example, if combining @code{g++} and @code{gfortran}, it is necessary to add
@verbatim
-L/usr/lib -lmpi_f77 -lgfortran 
@end verbatim
when linking an executable by @code{g++}. Obviously, the path may be different from this example on a particular machine.


@chapter Description of interface functions

In this chapter, detailed description of the solver interface functions with explanation of individual arguments is given

@section @code{bddcml_init}

@unnumberedsubsec C interface
@code{
void bddcml_init( int *nl, int *nsublev, int *lnsublev, int *nsub_loc_1, int *comm_init, int *verbose_level, int *numbase )
}
@unnumberedsubsec Fortran interface
@code{
subroutine bddcml_init(nl, nsublev,lnsublev, nsub_loc_1, comm_init, verbose_level, numbase)
}
@verbatim
      integer, intent(in) :: nl
      integer, intent(in) :: lnsublev
      integer, intent(in) ::  nsublev(lnsublev)
      integer, intent(inout):: nsub_loc_1 
      integer, intent(in):: comm_init 
      integer, intent(in):: verbose_level 
      integer, intent(in) :: numbase
@end verbatim

@unnumberedsubsec Description
Prepares internal data structures for the solver. 

@unnumberedsubsec Parameters

@table @code
@item nl
given number of levels, @code{nl} >= 2, @code{nl} = 2 corresponds to standard (two-level) BDDC method

@item nsublev
array with GLOBAL numbers of subdomains for each level. Need to be monotonically decreasing 
from @code{nsublev(1) = sum(nsub_loc_1)} to @code{nsublev(nl) = 1}

@item lnsublev
length of array @code{nsublev} - should match @code{nl}

@item nsub_loc_1 
LOCAL number of subdomains assigned to the process.
@itemize
@item >= 0 number of local subdomains - sum up across processes to nsublev[0]
@item -1   let solver decide, the value is returned ( determining linear partition )
@end itemize

@item comm_init 
initial global communicator (possibly @code{MPI_COMM_WORLD}). This should be communicator in Fortran.
When called from C, it should NOT be of type @code{MPI_Comm} but of type @code{int *}, and user should 
use the @code{MPI_Comm_c2f} function to convert the C @code{MPI_Comm} communicator to Fortran 
communicator of type @code{int *}. 

@item verbose_level 
level of verbosity
@itemize
@item     0 - only errors printed
@item     1 - some output
@item     2 - detailed output
@end itemize

@item numbase
first index of arrays ( 0 for C, 1 for Fortran )
@end table 



@page
@section @code{bddcml_upload_global_data}

@unnumberedsubsec C interface
@code{
void bddcml_upload_global_data( int *nelem, int *nnod, int *ndof, int *ndim, int *meshdim, 
                                int *inet, int *linet, int *nnet, int *lnnet, int *nndf, int *lnndf, 
                                double *xyz, int *lxyz1, int *lxyz2,
                                int *ifix, int *lifix, double *fixv, int *lfixv, double *rhs, int *lrhs, double *sol, int *lsol, int *idelm, 
                                int *neighbouring, int *load_division_int )
}
@unnumberedsubsec Fortran interface
@code{
subroutine bddcml_upload_global_data(nelem,nnod,ndof,ndim,meshdim,&
                                     inet,linet,nnet,lnnet,nndf,lnndf,xyz,lxyz1,lxyz2,&
                                     ifix,lifix, fixv,lfixv, rhs,lrhs, sol,lsol, idelm, &
                                     neighbouring, load_division_int)
}
@verbatim
      integer, intent(in):: nelem
      integer, intent(in):: nnod
      integer, intent(in):: ndof
      integer, intent(in) :: ndim 
      integer, intent(in) :: meshdim
      integer, intent(in):: linet
      integer, intent(in)::  inet(linet)
      integer, intent(in):: lnnet
      integer, intent(in)::  nnet(lnnet)
      integer, intent(in):: lnndf
      integer, intent(in)::  nndf(lnndf)
      integer, intent(in):: lxyz1, lxyz2
      real(kr), intent(in):: xyz(lxyz1,lxyz2)
      integer, intent(in):: lifix
      integer, intent(in)::  ifix(lifix)
      integer, intent(in):: lfixv
      real(kr), intent(in):: fixv(lfixv)
      integer, intent(in):: lrhs
      real(kr), intent(in):: rhs(lrhs)
      integer, intent(in):: lsol
      real(kr), intent(in):: sol(lsol)
      integer, intent(in) :: idelm  
      integer, intent(in) :: neighbouring 
      integer, intent(in) :: load_division_int
@end verbatim

@unnumberedsubsec Description
If no distribution of data exists in the user application, it may be left to the solver. 
This routine loads global information on mesh connectivity and coordinates. 
Matrix is passed as unassembled matrices of individual elements which will be read from opened file unit @code{idelm} 
and assembled within the solver.
If partitionining into subdomains on the basic level exists in user's application, 
routine @code{bddcml_upload_subdomain_data} should be used instead.


@unnumberedsubsec Parameters

@table @code

@item nelem
GLOBAL number of elements

@item nnod
GLOBAL number of nodes

@item ndof
GLOBAL number of degrees of freedom, i.e. size of matrix

@item ndim 
number of space dimensions

@item meshdim
mesh dimension.  For 3D elements = @code{ndim}, for 3D shells = 2, for 3D beams  = 1

@item inet
GLOBAL array with Indices of Nodes on ElemenTs - this defines connectivity of the mesh. 

@item linet
length of array @code{inet}. It is given as a sum of entries in array @code{nnet}.

@item nnet
GLOBAL array with Number of Nodes on ElemenTs. For each element, it gives number of nodes it is connected to.
This is important to locate element entries in array @code{inet}

@item lnnet
length of array @code{nnet}. It is equal to @code{nelem}.

@item nndf
GLOBAL array with Number of Nodal Degrees of Freedom. For each node, it gives number of attached degrees of freedom.

@item lnndf
length of array @code{nndf}. It is equal to @code{nnod}.

@item xyz
GLOBAL Coordinates of nodes as one array (all X, all Y, all Z) or as two-dimensional array in Fortran (X | Y | Z).
Rows are defined by nodes, columns are defined by dimension.

@item lxyz1,lxyz2
dimensions of array @code{xyz}. In C, lenght of @code{xyz} is defined as @code{lxyz1 * lxyz2}. In Fortran,
dimension of @code{xyz} is given used as @code{xyz(lxyz1,lxyz2)}.
The @code{lxyz1} is equal to @code{nnod}. The @code{lxyz2} is equal to @code{ndim}.

@item ifix
GLOBAL array of Indices of FIXed variables - all degrees of freedom with Dirichlet boundary condition are marked by 1, degrees of freedom not prescribed are marked by 0,
i.e. non-zero entries determine fixed degrees of freedom. 
The values of prescribed boundary conditions are given by corresponding entries of array @code{fixv}.

@item lifix
length of array @code{ifix}, equal to @code{ndof}.

@item fixv
GLOBAL array of FIXed Variables - where @code{ifix} is non-zero, @code{fixv} stores value of Dirichlet boundary condition. Where @code{ifix} is zero, corresponding value in @code{fixv} is meaningless.

@item lfixv
length of array @code{fixv}, equal to @code{ndof}.

@item rhs
GLOBAL array with Right-Hand Side

@item lrhs
length of array @code{rhs}, equal to @code{ndof}.

@item sol
GLOBAL array with initial SOLution guess. This is used as initial approximation for iterative method.

@item lsol
length of array @code{sol}, equal to @code{ndof}.

@item idelm
opened Fortran unit with unformatted file with element matrices

@item neighbouring 
how many nodes should be shared by two elements to call them adjacent in graph. 
This parameter is used for division of mesh on the basic level by @code{ParMETIS} or @code{METIS}. 
Often, one gets better results if he specifies this number to define adjacency only if elements share a face in 3D
or edge in 2D. E.g. for linear tetrahedra, the recommended value is 3.

@item load_division_int
Should division from file @file{partition_l1.ES} be used? ( 0 - partition is created in the solver, 1 - partition is read)
If partition is read, the file contains for each element, number of subdomain it belongs to.
Begins from 1.

@end table


@page
@section @code{bddcml_upload_subdomain_data}

@unnumberedsubsec C interface
@code{
void bddcml_upload_subdomain_data( int *nelem, int *nnod, int *ndof, int *ndim, int *meshdim,
                                   int *isub, int *nelems, int *nnods, int *ndofs, 
                                   int *inet, int *linet, int *nnet, int *lnnet, int *nndf, int *lnndf, 
                                   int *isngn, int *lisngn, int *isvgvn, int *lisvgvn, int *isegn, int *lisegn, 
                                   double *xyz, int *lxyz1, int *lxyz2, 
                                   int *ifix, int *lifix, double *fixv, int *lfixv, 
                                   double *rhs, int *lrhs, int *is_rhs_complete,
                                   double *sol, int *lsol, 
                                   int *matrixtype, int *i_sparse, int *j_sparse, double *a_sparse, int *la, int *is_assembled_int, 
                                   double *user_constraints, int *luser_constraints1, int *luser_constraints2,
                                   double *element_data, int *lelement_data1, int *lelement_data2,
                                   double *dof_data, int *ldof_data );
}
@unnumberedsubsec Fortran interface
@code{
subroutine bddcml_upload_subdomain_data(nelem, nnod, ndof, ndim, meshdim, &
                                        isub, nelems, nnods, ndofs, &
                                        inet,linet, nnet,lnnet, nndf,lnndf, &
                                        isngn,lisngn, isvgvn,lisvgvn, isegn,lisegn, &
                                        xyz,lxyz1,lxyz2, &
                                        ifix,lifix, fixv,lfixv, &
                                        rhs,lrhs, is_rhs_complete_int, &
                                        sol,lsol, &
                                        matrixtype, i_sparse, j_sparse, a_sparse, la, is_assembled_int,&
                                        user_constraints,luser_constraints1,luser_constraints2,&
                                        element_data,lelement_data1,lelement_data2, &
                                        dof_data,ldof_data)
}
@verbatim
      integer, intent(in):: nelem
      integer, intent(in):: nnod
      integer, intent(in):: ndof
      integer, intent(in):: ndim
      integer, intent(in):: meshdim
      integer, intent(in):: isub
      integer, intent(in):: nelems
      integer, intent(in):: nnods
      integer, intent(in):: ndofs
      integer, intent(in):: linet
      integer, intent(in)::  inet(linet)
      integer, intent(in):: lnnet
      integer, intent(in)::  nnet(lnnet)
      integer, intent(in):: lnndf
      integer, intent(in)::  nndf(lnndf)
      integer, intent(in):: lisngn
      integer, intent(in)::  isngn(lisngn)
      integer, intent(in):: lisvgvn
      integer, intent(in)::  isvgvn(lisvgvn)
      integer, intent(in):: lisegn
      integer, intent(in)::  isegn(lisegn)
      integer, intent(in):: lxyz1, lxyz2
      real(kr), intent(in):: xyz(lxyz1,lxyz2)
      integer, intent(in):: lifix
      integer, intent(in)::  ifix(lifix)
      integer, intent(in):: lfixv
      real(kr), intent(in):: fixv(lfixv)
      integer, intent(in):: lrhs
      real(kr), intent(in):: rhs(lrhs)
      integer, intent(in):: lsol
      real(kr), intent(in):: sol(lsol)
      integer, intent(in)::  is_rhs_complete_int  
      integer, intent(in)::  matrixtype 
      integer, intent(in)::  i_sparse(la)  
      integer, intent(in)::  j_sparse(la)  
      real(kr), intent(in):: a_sparse(la)  
      integer, intent(in)::  la            
      integer, intent(in)::  is_assembled_int 
      integer, intent(in)::  luser_constraints1
      integer, intent(in)::  luser_constraints2
      real(kr), intent(in)::user_constraints(luser_constraints1*&
                                             luser_constraints2)
      integer, intent(in)::  lelement_data1 
      integer, intent(in)::  lelement_data2 
      real(kr), intent(in):: element_data(lelement_data1*lelement_data2) 
      integer, intent(in)::  ldof_data  
      real(kr), intent(in):: dof_data(ldof_data) 

@end verbatim

@unnumberedsubsec Description
If distribution of data into subdomains exists already in the user application, data should be loaded into the solver using this routine.
It may be called repeatedly by each process if more than one subdomain are assigned to that process.
It loads the local mesh of the subdomain and assembled subdomain matrix in the coordinate format. 
Most data are localized to subdomain.

If partitionining into subdomains does not exist in user's application, 
routine @code{bddcml_upload_global_data} should be preferred.


@unnumberedsubsec Parameters

@table @code

@item nelem
GLOBAL number of elements

@item nnod
GLOBAL number of nodes

@item ndof
GLOBAL number of degrees of freedom, i.e. size of matrix

@item ndim 
number of space dimensions

@item meshdim
mesh dimension.  For 3D elements = @code{ndim}, for 3D shells = 2, for 3D beams  = 1

@item isub
GLOBAL index of subdomain which is loaded

@item nelems
LOCAL number of elements in subdomain

@item nnods
LOCAL number of nodes in subdomain mesh

@item ndofs
LOCAL number of degrees of freedom in subdomain mesh

@item inet
LOCAL array with Indices of Nodes on ElemenTs - this defines connectivity of the subdomain mesh. 

@item linet
length of array @code{inet}. It is given as a sum of entries in array @code{nnet}.

@item nnet
LOCAL array with Number of Nodes on ElemenTs. For each element, it gives number of nodes it is connected to.
This is important to locate element entries in array @code{inet}

@item lnnet
length of array @code{nnet}. It is equal to @code{nelems}.

@item nndf
LOCAL array with Number of Nodal Degrees of Freedom. For each node, it gives number of attached degrees of freedom.

@item lnndf
length of array @code{nndf}. It is equal to @code{nnods}.

@item isngn
array of Indices of Subdomain Nodes in Global Numbering (local to global map of nodes). For each local node gives the global index in original mesh.

@item lisngn
length of array @code{isngn}. It is equal to @code{nnods}.

@item isvgvn
array of Indices of Subdomain Variables in Global Variable Numbering (local to global map of variables). For each local degree of freedom gives the global index in original matrix.

@item lisvgvn
length of array @code{isvgvn}. It is equal to @code{ndofs}.

@item isegn
array of Indices of Subdomain Elements in Global Numbering (local to global map of elements). For each subdomain element gives global number in original mesh.

@item lisegn
length of array @code{isegn}. It is equal to @code{nelems}.

@item xyz
LOCAL array with coordinates of nodes as one array (all X, all Y, all Z) or as two-dimensional array in Fortran (X | Y | Z).
Rows are defined by nodes, columns are defined by dimension.

@item lxyz1,lxyz2
dimensions of array @code{xyz}. In C, lenght of @code{xyz} is defined as @code{lxyz1 * lxyz2}. In Fortran,
dimension of @code{xyz} is used as @code{xyz(lxyz1,lxyz2)}. 
The @code{lxyz1} is equal to @code{nnods}. The @code{lxyz2} is equal to @code{ndim}.

@item ifix
LOCAL array of Indices of FIXed variables - all degrees of freedom with Dirichlet boundary condition are marked by 1, degrees of freedom not prescribed are marked by 0,
i.e. non-zero entries determine fixed degrees of freedom.
The values of prescribed boundary conditions are given by corresponding entries of array @code{fixv}.

@item lifix
length of array @code{ifix}, equal to @code{ndofs}.

@item fixv
LOCAL array of FIXed Variables - where @code{ifix} is non-zero, @code{fixv} stores value of Dirichlet boundary condition. Where @code{ifix} is zero, corresponding value in @code{fixv} is meaningless.

@item lfixv
length of array @code{fixv}, equal to @code{ndofs}.

@item rhs
LOCAL array with Right-Hand Side. Values at nodes repeated among subdomains are copied and not weighted. 

@item lrhs
length of array @code{rhs}, equal to @code{ndofs}.

@item is_rhs_complete
is the subdomain right-hand side complete? 
@itemize 
@item 0 - no, e.g. if only local subassembly of right-hand side was performed - interface values are not fully assembled,
solver does not apply weights
@item 1 - yes, e.g. if local right-hand side is a restriction of the global array to the subdomain - interface values are
complete and repeated for more subdomains, solver applies weights to handle multiplicity of these entries
@end itemize 

@item sol
LOCAL array with initial SOLution guess. This is used as initial approximation for iterative method. 

@item lsol
length of array @code{sol}, equal to @code{ndofs}.

@item matrixtype 
Type of the matrix. This parameter determines storage and underlying direct method of the @code{MUMPS} solver for factorizations.
Matrix is loaded in coordinate format by three arrays described below. Options are
@itemize
@item 0 
unsymmetric - whole matrix is loaded
@item 1 
symmetric positive definite - only upper triangle of the matrix is loaded
@item 2 
general symmetric - only upper triangle of the matrix is loaded
@end itemize

@item i_sparse
array of row indices of non-zero entries in LOCAL numbering with respect to subdomain degrees of freedom, 
i.e. indices are in the range [@code{0}, @code{ndofs-1}] in C ( and in [@code{1}, @code{ndofs}] in Fortran)

@item j_sparse
array of column indices of non-zero entries in LOCAL numbering with respect to subdomain degrees of freedom,
see @code{i_sparse} for their ranges

@item a_sparse  
array of values of non-zero entries

@item la  
length of previous arrays @code{i_sparse}, @code{j_sparse}, @code{a_sparse} ( equal to number of non-zeros if the matrix is loaded already assembled )

@item is_assembled_int  
is the matrix assembled? 
The solver comes with fast assembly routine so the users might want to pass just unassembled matrix for each subdomain 
(i.e. copy of element matrices equipped with global indexing), and let the solver assemble it.
@itemize 
@item 0 - no, it can contain repeated entries, will be assembled by solver
@item 1 - yes, it is sorted and does not contain repeated index pairs
@end itemize 

@item luser_contraints1, luser_constraints2
dimension of array with user constraints, @code{luser_constraints2} should equal to @code{nnods} if user wants to use this feature. Otherwise both can be set to 0.

@item user_contraints
linearized matrix of user's constraints, one row per constraint, stored row-by-row. Each row has entries for all nodes (in columns) and may contain several constraints (at rows). It may be left empty if no additional contraints are demanded by call to @code{bddcml_setup_preconditioner}. 

@item lelement_data1, lelement_data2
dimension of array with data for elements, @code{lelement_data2} should equal to @code{nelems} if user wants to use this feature. Otherwise both can be set to 0.

@item element_data
linearized matrix with element data, one row per field, stored row-by-row. Each row has entries for all elements (in columns).
Single row is currently optionally used for generating interface weigths in the BDDC method, so called @math{\rho}-scaling.

@item ldof_data
dimension of array with data for subdomain degrees of freedom, @code{ldof_data} should equal to @code{ndofs} if user wants to use this feature. Otherwise it can be set to 0.

@item dof_data
coefficients for each local degree of freedom currently optionally used for generating interface weigths in the BDDC method. 
The array should be positive, @code{dof_data} > 0.


@page
@section @code{bddcml_setup_preconditioner}

@unnumberedsubsec C interface
@code{
void bddcml_setup_preconditioner( int *matrixtype, int *use_defaults_int,
                                  int *parallel_division_int, 
                                  int *use_arithmetic_constraints_int, 
                                  int *use_adaptive_constraints_int,
                                  int *use_user_constraints_int,
                                  int *weights_type );
}
@unnumberedsubsec Fortran interface
@code{
subroutine bddcml_setup_preconditioner(matrixtype, use_defaults_int, &
                                       parallel_division_int, &
                                       use_arithmetic_constraints_int, &
                                       use_adaptive_constraints_int, &
                                       use_user_constraints_int, &
                                       weights_type)
}
@verbatim
      integer,intent(in) :: matrixtype 
      integer,intent(in) :: use_defaults_int
      integer,intent(in) :: parallel_division_int
      integer,intent(in) :: use_arithmetic_constraints_int
      integer,intent(in) :: use_adaptive_constraints_int
      integer,intent(in) :: use_user_constraints_int
      integer,intent(in) :: weights_type
@end verbatim

@unnumberedsubsec Description
Calling this function prepares internal data of the preconditioner. Local factorizations are performed for each subdomain at each level and also
the resulting coarse problem on the final level is factored. This might be quite costly routine. 
Once the preconditioner is set-up, it can be reused for new right hand sides (if the matrix is not changed) 
by calling @code{bddcml_upload_subdomain_data} followed by @code{bddcml_solve}.

@unnumberedsubsec Parameters

@table @code

@item matrixtype 
Type of the matrix. This parameter determines storage and underlying direct method of the @code{MUMPS} solver for factorizations.
Should keep the value inserted to @code{bddcml_upload_subdomain_data}. Options are
@itemize
@item 0 
unsymmetric - whole matrix is loaded
@item 1 
symmetric positive definite - only upper triangle of the matrix is loaded
@item 2 
general symmetric - only upper triangle of the matrix is loaded
@end itemize

@item use_defaults_int
If @code{> 0}, other options are ignored and the solver uses default options.

@item parallel_division_int
If @code{> 0}, solver will use @code{ParMETIS} to create division on first level. 
This option is only used for global input (@code{bddcml_upload_global_data}) and only applies to the first level. Otherwise, @code{METIS} is used.
Default is @code{1}.

@item use_arithmetic_constraints_int
If @code{> 0}, solver will use continuity of arithmetic averages on faces in 2D and faces and edges in 3D to form the coarse space. 
Default is @code{1}.

@item use_adaptive_constraints_int
If @code{> 0}, solver will use adaptive averages on faces in 2D and faces in 3D. 
This might be costly and should be used for very ill-conditioned problems. A generalized eigenvalue problem is solved at each face and weighted averages are
derived from eigenvectors. For solving individual eigenproblems, @code{BLOPEX} package is used.
Default is @code{0}.

@item use_user_constraints_int
If @code{> 0}, solver will use array @code{USER_CONSTRAINTS} supplied in routine @code{bddcml_upload_subdomain_data} for construction of additional constraints on subdomain faces.
This may be used e.g. for enforcing flux-based constraints for advection-diffusion problems.
Default is @code{0}.
@end table

@item weights_type
Type of weights to be used on interface (default 0). Possible choices
@itemize
@item 0 -- weights computed by cardinality, i.e. arithmetic average, the mean value of solution from neighbouring subdomains.
Good choice for many problem types except those with large variations in material coefficients and/or sizes of elements.
@item 1 -- weights from diagonal stiffness, corresponding diagonal entry in the matrix. 
Good choice for symmetric positive definite problems with large variations in material coefficients and/or sizes of elements.
Not good for homogenous problems with irregular subdomains, such as those from graph partitioners, in combination with nodal elements.
This option takes into account different sizes of elements and material coefficients.
@item 2 -- weights based on loaded element data. For this choice, the first row of array @code{element_data}
from function @code{bddcml_upload_subdomain_data} must contain element coefficients to be used here.
This allows definition of the so called @math{\rho}-scaling.
Good choice for problems with large variations in material coefficients if irregular subdomains from graph partitioners are used in combination
with nodal finite elements. 
@item 3 -- weights based on loaded data for degees of freedom. For this choice, array @code{dof_data}
from function @code{bddcml_upload_subdomain_data} must contain coefficients for each subdomain degree of freedom.
This allows definition of general user-defined weigths on degrees of freedom tailored to particular applications.
@end itemize

@page
@section @code{bddcml_solve}

@unnumberedsubsec C interface
@code{
void bddcml_solve( int *comm_all, int *method, double *tol, int *maxit, int *ndecrmax, 
                   int *num_iter, int *converged_reason, double *condition_number);
}
@unnumberedsubsec Fortran interface
@code{
subroutine bddcml_solve(comm_all,method,tol,maxit,ndecrmax, &
                        num_iter,converged_reason,condition_number)
}
@verbatim
      integer, intent(in) :: comm_all 
      integer, intent(in) :: method
      real(kr), intent(in) :: tol
      integer, intent(in) :: maxit
      integer, intent(in) :: ndecrmax
      integer, intent(out) :: num_iter
      integer, intent(out) :: converged_reason
      real(kr), intent(out) :: condition_number
@end verbatim

@unnumberedsubsec Description
This function launches the solution procedure for prepared data. System is solved either by preconditioned conjugate gradient (PCG) method or by 
preconditioned stabilized Bi-Conjugate Gradient (BiCGstab) method.

@unnumberedsubsec Parameters

@table @code
@item comm_all 
global communicator. Should be the same as @code{comm_init} for @code{bddcml_init} function.

@item method
Krylov subspace iterative method
@itemize
@item -1 - use defaults - @code{tol}, @code{maxit}, and @code{ndecrmax} not accessed, BiCGstab method used by default,
@item  0 - use PCG,
@item  1 - use BiCGstab.
@end itemize

@item tol
desired accuracy of relative residual (default 1.e-6).

@item maxit
limit on number of iterations (default 1000).

@item ndecrmax
limit on number of iterations with non-decreasing residual (default 30) - used to stop a diverging process.

@item num_iter
on output, resulting number of iterations.

@item converged_reason
on output, contains reason for convergence/divergence
@itemize
   @item 0 - converged relative residual,
   @item -1 - reached limit on number of iterations,
   @item -2 - reached limit on number of iterations with non-decreasing residual.
@end itemize

@item condition_number
on output, estimated condition number ( for PCG only ).

@end table


@page
@section @code{bddcml_download_local_solution}

@unnumberedsubsec C interface
@code{
void bddcml_download_local_solution( int *isub, double *sols, int *lsols )
}
@unnumberedsubsec Fortran interface
@code{
subroutine bddcml_download_local_solution(isub, sols,lsols)
}
@verbatim
      integer, intent(in)::  isub
      integer, intent(in)::  lsols
      real(kr), intent(out):: sols(lsols)
@end verbatim

@unnumberedsubsec Description
Subroutine for getting local solution, i.e. restriction of solution vector to subdomain (no weights are applied).

@unnumberedsubsec Parameters

@table @code
@item isub
GLOBAL index of subdomain

@item sols
LOCAL array of solution restricted to subdomain

@item lsols
length of array @code{sols}, equal to @code{ndofs}.

@end table


@page
@section @code{bddcml_download_global_solution}

@unnumberedsubsec C interface
@code{
void bddcml_download_global_solution( double *sol, int *lsol )
}
@unnumberedsubsec Fortran interface
@code{
subroutine bddcml_download_global_solution(sol, lsol)
}
@verbatim
      integer, intent(in)::  lsol
      real(kr), intent(out):: sol(lsol)
@end verbatim

@unnumberedsubsec Description
This function downloads global solution of the system from the solver at the root process.

@unnumberedsubsec Parameters

@table @code
@item sol
GLOBAL array of solution

@item lsol
length of array @code{sol}, equal to @code{ndof}

@end table


@page
@section @code{bddcml_download_local_reactions}

@unnumberedsubsec C interface
@code{
void bddcml_download_local_reactions( int *isub, double *reas, int *lreas )
}
@unnumberedsubsec Fortran interface
@code{
subroutine bddcml_download_local_reactions(isub, reas,lreas)
}
@verbatim
      integer, intent(in)::  isub
      integer, intent(in)::  lreas
      real(kr), intent(out):: reas(lreas)
@end verbatim

@unnumberedsubsec Description
Subroutine for getting local reactions at unknowns fixed by Dirichlet boundary conditions, 
i.e. restriction of vector of reactions to subdomain (no weights are applied).
Global vector of reactions is given by @code{r = Ax - b}, where @code{A} is the matrix WITHOUT Dirichlet boundary conditions fixed,
@code{x} is the solution, and @code{b} the original right-hand side.
@unnumberedsubsec Parameters

@table @code
@item isub
GLOBAL index of subdomain

@item reas
LOCAL array of vector of reactions restricted to subdomain. It contains nonzeros only at unknowns marked in the IFIX array
(see @code{bddcml_upload_local_data}). 

@item lreas
length of array @code{reas}, equal to @code{ndofs}.

@end table

@page
@section @code{bddcml_download_global_reactions}

@unnumberedsubsec C interface
@code{
void bddcml_download_global_reactions( double *rea, int *lrea )
}
@unnumberedsubsec Fortran interface
@code{
subroutine bddcml_download_global_reactions(rea, lrea)
}
@verbatim
      integer, intent(in)::  lrea
      real(kr), intent(out):: rea(lrea)
@end verbatim

@unnumberedsubsec Description
Subroutine for getting global reactions at unknowns fixed by Dirichlet boundary conditions at the root process. 
Global vector of reactions is given by @code{r = Ax - b}, where @code{A} is the matrix WITHOUT Dirichlet boundary conditions fixed,
@code{x} is the solution, and @code{b} the original right-hand side.

@unnumberedsubsec Parameters

@table @code
@item rea
GLOBAL array of reactions. It contains nonzeros only at unknowns marked in the IFIX array
(see @code{bddcml_upload_global_data}). 

@item lrea
length of array @code{rea}, equal to @code{ndof}

@end table

@page

@section @code{bddcml_dotprod_subdomain}

@unnumberedsubsec C interface
@code{
void bddcml_dotprod_subdomain( int *isub, double *vec1, int *lvec1, double *vec2, int *lvec2, double *dotprod )
}
@unnumberedsubsec Fortran interface
@code{
subroutine bddcml_dotprod_subdomain( isub, vec1,lvec1, vec2,lvec2, dotprod )
}
@verbatim
      integer, intent(in) ::  isub 
      integer, intent(in) ::  lvec1  
      real(kr), intent(in) :: vec1(lvec1)
      integer, intent(in) ::  lvec2      
      real(kr), intent(in) :: vec2(lvec2)
      real(kr), intent(out) :: dotprod
@end verbatim

@unnumberedsubsec Description
Auxiliary subroutine to compute scalar product of two vectors of lenght of
subdomain exploiting interface weights from the solver. This routine is useful 
if we want to compute global norm or dot-product based on vectors restricted to 
subdomains. Since interface values are contained in several vectors for
several subdomains, this dot product or norm cannot be determined without
weights.

@unnumberedsubsec Parameters

@table @code
@item isub
GLOBAL index of subdomain

@item vec1
LOCAL first vector for dot-product

@item lvec1        
length of @code{vec1}

@item vec2
LOCAL second vector for dot-product, may be same array as @code{vec1}

@item lvec2        
length of @code{vec2}, should be same as @code{lvec1}

@item dotprod
on exit, returns vec1' * weights * vec2

@end table


@page
@section @code{bddcml_finalize}

@unnumberedsubsec C interface
@code{
void bddcml_finalize( )
}
@unnumberedsubsec Fortran interface
@code{
subroutine bddcml_finalize
}

@unnumberedsubsec Description
Finalization of the solver. All internal data are deallocated.

@unnumberedsubsec Parameters
This routine currently does not take any arguments.


@bye

